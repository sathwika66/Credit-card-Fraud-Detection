# -*- coding: utf-8 -*-
"""Credit Card Fraud Detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tKAaf7BDftos0ao8zwLsOPbgtqz9fqC7
"""

import pandas as pd
from collections import Counter
import itertools
import numpy as np # linear algebra
import matplotlib.pyplot as plt # data visualization
import seaborn as sns # statistical data visualization
!pip install --upgrade chart-studio

data = pd.read_csv('/content/creditcard.csv')

data.head()

data.describe()

data.isnull().values.any()

data["Amount"].describe()

non_fraud = len(data[data.Class == 0])
fraud = len(data[data.Class == 1])
fraud_percent = (fraud / (fraud + non_fraud)) * 100

print("Number of Genuine transactions: ", non_fraud)
print("Number of Fraud transactions: ", fraud)
print("Percentage of Fraud transactions: {:.4f}".format(fraud_percent))

f,ax = plt.subplots(figsize = (15, 15))
sns.heatmap(data.corr(), annot = True, linewidths = .5, fmt = '.2f')
plt.show()

import matplotlib.pyplot as plt

labels = ["Genuine", "Fraud"]
count_classes = data.value_counts(data['Class'], sort= True)
count_classes.plot(kind = "bar", rot = 0)
plt.title("Visualization of Labels")
plt.ylabel("Count")
plt.xticks(range(2), labels)
plt.show()

print("Class as pie chart:")
fig, ax = plt.subplots(1, 1)
ax.pie(data.Class.value_counts(),autopct='%1.1f%%', labels=['Genuine','Fraud'], colors=['yellowgreen','r'])
plt.axis('equal')
plt.ylabel('')

X = data.drop(['Class'], axis = 1)
Y = data["Class"]
print(X.shape)
print(Y.shape)
# getting just the values for the sake of processing
# (its a numpy array with no columns)
xData = X.values
yData = Y.values

import numpy as np
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
data["NormalizedAmount"] = scaler.fit_transform(data["Amount"].values.reshape(-1, 1))
data.drop(["Amount", "Time"], inplace= True, axis= 1)

Y = data["Class"]
X = data.drop(["Class"], axis= 1)

def enable_plotly_in_cell():
  import IPython
  from plotly.offline import init_notebook_mode
  display(IPython.core.display.HTML('''<script src="/static/components/requirejs/require.js"></script>'''))
  init_notebook_mode(connected=False)
from plotly.offline import iplot
import plotly.graph_objs as go

enable_plotly_in_cell()
trace1 = go.Box(
    x = data.V7,
    name = 'V7',
    marker = dict(color = 'blue')
    )
box_data = [trace1]
iplot(box_data)

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)

print("Shape of train_X: ", X_train.shape)
print("Shape of test_X: ", X_test.shape)

#Decision Tree Classifier
from sklearn.tree import DecisionTreeClassifier
decision_tree = DecisionTreeClassifier()

decision_tree.fit(X_train,y_train)
predictions_dt = decision_tree.predict(X_test)
decision_tree_score = decision_tree.score(X_test,y_test) * 100

from sklearn import metrics
print("Accuracy:",decision_tree_score)

from sklearn.metrics import accuracy_score, precision_score, confusion_matrix, recall_score, f1_score


def metrics(actuals, predictions):
    print("Accuracy: {:.5f}".format(accuracy_score(actuals, predictions)))
    print("Precision: {:.5f}".format(precision_score(actuals, predictions)))
    print("Recall: {:.5f}".format(recall_score(actuals, predictions)))
    print("F1-score: {:.5f}".format(f1_score(actuals, predictions)))

print("Evaluation of Decision Tree Model")
print()
metrics(y_test, predictions_dt.round())

confusion_matrix_dt = confusion_matrix(y_test, predictions_dt.round())
print("Confusion Matrix - Decision Tree")
print(confusion_matrix_dt)

from sklearn import metrics
print('Mean Squared Error (MSE):', metrics.mean_squared_error(y_test, predictions_dt))
print('Root Mean Squared Error (RMSE):', np.sqrt(metrics.mean_squared_error(y_test, predictions_dt)))

#Random Forest
from sklearn.ensemble import RandomForestClassifier

#Create a Gaussian Classifier
clf=RandomForestClassifier(n_estimators=100)

#Train the model using the training sets y_pred=clf.predict(X_test)
clf.fit(X_train,y_train)

y_pred=clf.predict(X_test)

print(y_pred)

from sklearn import metrics
rdf_score=metrics.accuracy_score(y_test, y_pred)*100
print("Accuracy:",rdf_score)

from sklearn.metrics import accuracy_score, precision_score, confusion_matrix, recall_score, f1_score


def metrics(actuals, predictions):
    print("Accuracy: {:.5f}".format(accuracy_score(actuals, predictions)))
    print("Precision: {:.5f}".format(precision_score(actuals, predictions)))
    print("Recall: {:.5f}".format(recall_score(actuals, predictions)))
    print("F1-score: {:.5f}".format(f1_score(actuals, predictions)))

cm_resampled = confusion_matrix(y_test, y_pred.round())
print("Confusion Matrix - Random Forest")
print(cm_resampled)

print("Evaluation of Random Forest Model")
print()

metrics(y_test,y_pred.round())

from sklearn import metrics
print('Mean Squared Error (MSE):', metrics.mean_squared_error(y_test, y_pred))
print('Root Mean Squared Error (RMSE):', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))

#Linear Regression

from sklearn.linear_model import LinearRegression
model = LinearRegression()
model.fit(X_train, y_train)

y_pred=model.predict(X_test)
from sklearn import metrics
lr_score=metrics.r2_score(y_test, y_pred)*100
print("Accuracy:",lr_score)

# Intercept & Coef
print("Intercept :", model.intercept_)
print("Coef :", model.coef_)

# New data (real , estimated)
new_data = pd.DataFrame({'real': y_test, 'estimated': y_pred})
new_data

from sklearn import metrics
print('Mean Squared Error (MSE):', metrics.mean_squared_error(y_test, y_pred))
print('Root Mean Squared Error (RMSE):', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))

from sklearn.metrics import accuracy_score, precision_score, confusion_matrix, recall_score, f1_score


def metrics(actuals, predictions):
    print("Precision: {:.5f}".format(precision_score(actuals, predictions)))
    print("Recall: {:.5f}".format(recall_score(actuals, predictions)))
    print("F1-score: {:.5f}".format(f1_score(actuals, predictions)))

lr_resampled = confusion_matrix(y_test, y_pred.round())
print("Confusion Matrix - linear reggresion")
print(lr_resampled)

print("Evaluation of linear regression Model")
print()

metrics(y_test,y_pred.round())

print("Logistic Regression")

from sklearn.linear_model import LogisticRegression

logistic_model = LogisticRegression()

data = data.reset_index(drop=True)
data.shape

from sklearn import model_selection

array = data.values
X = array[:,0:20]
Y = array[:,20]

# Get Training and Validation sets
X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, test_size=0.2, random_state=7)

from sklearn.metrics import accuracy_score
from sklearn.linear_model import LogisticRegression
model = LogisticRegression()

model.fit(X_train, y_train)
predictions = model.predict(X_test)
logl_score = accuracy_score(predictions,y_test)*100

y_pred=model.predict(X_test)

from sklearn import metrics
logl_score=metrics.accuracy_score(y_test, y_pred)*100
print("Accuracy:",logl_score)

from sklearn import metrics
print('Mean Squared Error (MSE):', metrics.mean_squared_error(y_test, y_pred))
print('Root Mean Squared Error (RMSE):', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))

print("kmeans clustering")
from sklearn.cluster import KMeans

from sklearn.model_selection import train_test_split

X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, test_size=0.2, random_state=7)

kmeans=KMeans(n_clusters=2,random_state=0,algorithm="elkan",max_iter=10000)

kmeans.fit(X_train,Y_train)

predictions = kmeans.predict(X_test)

kmeans_score = accuracy_score(predictions,y_test)*100

y_pred=kmeans.predict(X_test)

from sklearn import metrics
kmeans_score=metrics.accuracy_score(y_test, y_pred)*100
print("Accuracy:",kmeans_score)

from sklearn import metrics
print('Mean Squared Error (MSE):', metrics.mean_squared_error(Y_test, y_pred))
print('Root Mean Squared Error (RMSE):', np.sqrt(metrics.mean_squared_error(Y_test, y_pred)))

print("Ensemble methods : logistic regression, linear regression, random forests--averaging")

data1 = pd.read_csv('/content/creditcard.csv')

YY = data1["Class"]
XX = data1.drop(["Class"], axis= 1)

from sklearn.ensemble import RandomForestRegressor

X_train, X_test, y_train, y_test = train_test_split(XX, YY, test_size=0.20)

model_0 = LogisticRegression()
model_1 = LinearRegression()
model_2 = RandomForestRegressor()

data1['Class'] = data['Class'].astype(int)
data1['V28'] = data['V28'].astype(int)
data1 = data1.astype({"Amount":'int'})
display(data1.dtypes)

data.isnull().sum()

model_0.fit(X_train,y_train)

model_1.fit(X_train,y_train)

model_2.fit(X_train,y_train)

pred_0 = model_0.predict(X_test)

pred_1 = model_1.predict(X_test)

pred_final = (pred_0+pred_1)/3.0
print(pred_final)

from sklearn.metrics import mean_squared_error
print(mean_squared_error(y_test, pred_final))

from sklearn.metrics import accuracy_score, precision_score, confusion_matrix, recall_score, f1_score


def metrics(actuals, predictions):
    print("Accuracy: {:.5f}".format(accuracy_score(actuals, predictions)))
    print("Precision: {:.5f}".format(precision_score(actuals, predictions)))
    print("Recall: {:.5f}".format(recall_score(actuals, predictions)))
    print("F1-score: {:.5f}".format(f1_score(actuals, predictions)))

print("Evaluation of Averaging")
print()
metrics(y_test, pred_final.round())

print("Bagging")

from sklearn.ensemble import BaggingRegressor

#model = BaggingRegressor(base_estimator = RandomForestClassifier())

X_train, X_test, y_train, y_test = train_test_split(
    XX, YY, test_size=0.20)

model.fit(X_train, y_train)
pred = model.predict(X_test)

print(mean_squared_error(y_test, pred))

from sklearn.metrics import accuracy_score, precision_score, confusion_matrix, recall_score, f1_score


def metrics(actuals, predictions):
    print("Accuracy: {:.5f}".format(accuracy_score(actuals, predictions)))
    print("Precision: {:.5f}".format(precision_score(actuals, predictions)))
    print("Recall: {:.5f}".format(recall_score(actuals, predictions)))
    print("F1-score: {:.5f}".format(f1_score(actuals, predictions)))

print("Evaluation of Bagging")
print()
metrics(y_test, pred.round())



